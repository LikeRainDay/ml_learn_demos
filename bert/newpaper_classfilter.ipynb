{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "1. 准备原始文本数据\n",
    "2. 将原始文本转换为bert相关输入格式\n",
    "3. 在bert之上加入新layer成下游任务模型\n",
    "4. 训练该下游任务模型\n",
    "5. 对新样本做推测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始样本数量： 320543\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 对数据进行清洗\n",
    "df_train = pd.read_csv(\"data/train.csv\")\n",
    "empty_title = (df_train['title2_zh'].isnull() \\\n",
    "              | df_train['title1_zh'].isnull() \\\n",
    "              | (df_train['title2_zh'] == '') \\\n",
    "              | (df_train['title2_zh'] == '0'))\n",
    "df_train = df_train[~empty_title]\n",
    "\n",
    "print(\"原始样本数量：\", len(df_train))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练样本数量： 2657\n"
     ]
    },
    {
     "data": {
      "text/plain": "                          text_a                          text_b      label\n0       苏有朋要结婚了，但网友觉得他还是和林心如比较合适  好闺蜜结婚给不婚族的秦岚扔花球，倒霉的秦岚掉水里笑哭苏有朋！  unrelated\n1  爆料李小璐要成前妻了贾乃亮模仿王宝强一步到位、快刀斩乱麻！  李小璐要变前妻了？贾乃亮可能效仿王宝强当机立断，快刀斩乱麻！     agreed\n2  为彩礼，母亲把女儿嫁给陌生男子，十年后再见面，母亲湿了眼眶  阿姨，不要彩礼是觉得你家穷，给你台阶下，不要以为我嫁不出去！  unrelated\n3         猪油是个宝，一勺猪油等于十副药，先备起来再说  传承千百的猪油为何变得人人唯恐避之不及？揭开猪油的四大谣言！  unrelated\n4                  剖析：香椿，为什么会致癌？            香椿含亚硝酸盐多吃会致癌？测完发现是谣言  disagreed",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_a</th>\n      <th>text_b</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>苏有朋要结婚了，但网友觉得他还是和林心如比较合适</td>\n      <td>好闺蜜结婚给不婚族的秦岚扔花球，倒霉的秦岚掉水里笑哭苏有朋！</td>\n      <td>unrelated</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>爆料李小璐要成前妻了贾乃亮模仿王宝强一步到位、快刀斩乱麻！</td>\n      <td>李小璐要变前妻了？贾乃亮可能效仿王宝强当机立断，快刀斩乱麻！</td>\n      <td>agreed</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>为彩礼，母亲把女儿嫁给陌生男子，十年后再见面，母亲湿了眼眶</td>\n      <td>阿姨，不要彩礼是觉得你家穷，给你台阶下，不要以为我嫁不出去！</td>\n      <td>unrelated</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>猪油是个宝，一勺猪油等于十副药，先备起来再说</td>\n      <td>传承千百的猪油为何变得人人唯恐避之不及？揭开猪油的四大谣言！</td>\n      <td>unrelated</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>剖析：香椿，为什么会致癌？</td>\n      <td>香椿含亚硝酸盐多吃会致癌？测完发现是谣言</td>\n      <td>disagreed</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 剔除过长的样本数据避免 bert 无法将整个输入序列放入记忆力不强的 GPU\n",
    "MAX_LENGTH = 30\n",
    "df_train = df_train[~(df_train.title1_zh.apply(lambda x: len(x)) > MAX_LENGTH)]\n",
    "df_train = df_train[~(df_train.title2_zh.apply(lambda x: len(x)) > MAX_LENGTH)]\n",
    "\n",
    "# 只采用1%训练数据\n",
    "SAMPLE_FRAC = 0.01\n",
    "df_train = df_train.sample(frac=SAMPLE_FRAC, random_state=9527)\n",
    "\n",
    "# 去除不必要的单位并重新民命标题内容\n",
    "df_train = df_train.reset_index()\n",
    "df_train = df_train.loc[:, ['title1_zh', 'title2_zh', 'label']]\n",
    "df_train.columns = ['text_a', 'text_b', 'label']\n",
    "\n",
    "# idempotence, 将结果另存为 tsv 供 PyTorch 使用\n",
    "df_train.to_csv(\"train.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "print(\"训练样本数量：\", len(df_train))\n",
    "df_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "由于样本数据中的unrelated 的数量为68% ,因此我们用的bert训练出的最少要超过68% 的baseline才可以："
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "unrelated    0.679338\nagreed       0.294317\ndisagreed    0.026346\nName: label, dtype: float64"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.label.value_counts() / len(df_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "对测试数据进行处理，满足格式要求"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "預測樣本數： 80126\n"
     ]
    },
    {
     "data": {
      "text/plain": "                            text_a                       text_b      Id\n0  萨拉赫人气爆棚!埃及总统大选未参选获百万选票 现任总统压力山大  辟谣！里昂官方否认费基尔加盟利物浦，难道是价格没谈拢？  321187\n1              萨达姆被捕后告诫美国的一句话，发人深思    10大最让美国人相信的荒诞谣言，如蜥蜴人掌控着美国  321190\n2    萨达姆此项计划没有此国破坏的话，美国还会对伊拉克发动战争吗          萨达姆被捕后告诫美国的一句话，发人深思  321189\n3              萨达姆被捕后告诫美国的一句话，发人深思  被绞刑处死的萨达姆是替身？他的此男人举动击破替身谣言！  321193\n4              萨达姆被捕后告诫美国的一句话，发人深思         中国川贝枇杷膏在美国受到热捧？纯属谣言！  321191",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_a</th>\n      <th>text_b</th>\n      <th>Id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>萨拉赫人气爆棚!埃及总统大选未参选获百万选票 现任总统压力山大</td>\n      <td>辟谣！里昂官方否认费基尔加盟利物浦，难道是价格没谈拢？</td>\n      <td>321187</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>萨达姆被捕后告诫美国的一句话，发人深思</td>\n      <td>10大最让美国人相信的荒诞谣言，如蜥蜴人掌控着美国</td>\n      <td>321190</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>萨达姆此项计划没有此国破坏的话，美国还会对伊拉克发动战争吗</td>\n      <td>萨达姆被捕后告诫美国的一句话，发人深思</td>\n      <td>321189</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>萨达姆被捕后告诫美国的一句话，发人深思</td>\n      <td>被绞刑处死的萨达姆是替身？他的此男人举动击破替身谣言！</td>\n      <td>321193</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>萨达姆被捕后告诫美国的一句话，发人深思</td>\n      <td>中国川贝枇杷膏在美国受到热捧？纯属谣言！</td>\n      <td>321191</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"data/test.csv\")\n",
    "df_test = df_test.loc[:, [\"title1_zh\", \"title2_zh\", \"id\"]]\n",
    "df_test.columns = [\"text_a\", \"text_b\", \"Id\"]\n",
    "df_test.to_csv(\"test.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "print(\"預測樣本數：\", len(df_test))\n",
    "df_test.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试数据样本树 / 训练数据样本书 = 30.2 倍\n"
     ]
    }
   ],
   "source": [
    "ratio = len(df_test) / len(df_train)\n",
    "print(\"测试数据样本树 / 训练数据样本书 = {:.1f} 倍\".format(ratio))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "将数据内容转化为 dataset 相容的格式内容"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "作为一个可以用来读取训练 / 测试集的 Dataset, 这是你需要彻底了解的部分，\n",
    "此 Dataset 每次將 tsv 里的一组成对句子转化成 BERT 相容的格式，并回传3哥 tensors：\n",
    "- tokens_tensor：两个句子合并后的索引序列，包含 [CLS] 與 [SEP]\n",
    "- segments_tensor：可以用来识别两个句子的界限 binary tensor\n",
    "- label_tensor：将分类目标转化为类别索引 tensor, 如果是测试集则回传 None\n",
    "\"\"\"\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class FakeNewsDataset(Dataset):\n",
    "    # 读取之前初始化后的 tsv 并初始化一部分参数\n",
    "    def __init__(self, mode, tokenizer):\n",
    "        # 一般训练会需要 dev set\n",
    "        assert mode in [\"train\", \"test\"]\n",
    "        self.mode = mode\n",
    "        # 大数据你会需要用 iterator = True\n",
    "        self.df = pd.read_csv(mode + \".tsv\", sep=\"\\t\").fillna(\"\")\n",
    "        self.len = len(self.df)\n",
    "        self.label_map = {'agreed': 0, 'disagreed': 1, 'unrelated': 2}\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    # 定义回传一些训练 / 测试数据函数\n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == \"test\":\n",
    "            text_a, test_b = self.df.iloc[idx, :2].values\n",
    "            label_tensor = None\n",
    "        else:\n",
    "            text_a, text_b, label = self.df.iloc[idx, :].values\n",
    "            label_id = self.label_map[label]\n",
    "            label_tensor = torch.tensor(label_id)\n",
    "\n",
    "        # 建立第一个句子的 bert tokens 并加入分割符号 [SEP]\n",
    "        word_pieces = [\"[CLS]\"]\n",
    "        tokens_a = self.tokenizer.tokenize(text_a)\n",
    "        print(tokens_a)\n",
    "        word_pieces += tokens_a + [\"[SEP]\"]\n",
    "        len_a = len(word_pieces)\n",
    "\n",
    "        # 第二个句子的 BERT tokens\n",
    "        tokens_b = self.tokenizer.tokenize(text_b)\n",
    "        word_pieces += tokens_b + [\"[SEP]\"]\n",
    "        len_b = len(word_pieces) - len_a\n",
    "\n",
    "        # 第二个句子的 BERT tokens\n",
    "        tokens_b = self.tokenizer.tokenize(text_b)\n",
    "        word_pieces += tokens_b + [\"[SEP]\"]\n",
    "        len_b = len(word_pieces) - len_a\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}